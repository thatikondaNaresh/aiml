{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Here are the answers:\n",
    "\n",
    "Q1:\n",
    "Bayes' theorem is a fundamental concept in probability theory that describes how to update the probability of a hypothesis (H) given new evidence (E). It provides a mathematical framework for making probabilistic predictions or classifications based on prior knowledge and new data.\n",
    "\n",
    "Q2:\n",
    "The formula for Bayes' theorem is:\n",
    "\n",
    "P(H|E) = P(E|H) * P(H) / P(E)\n",
    "\n",
    "where:\n",
    "\n",
    "- P(H|E) is the posterior probability of the hypothesis (H) given the evidence (E)\n",
    "- P(E|H) is the likelihood of the evidence (E) given the hypothesis (H)\n",
    "- P(H) is the prior probability of the hypothesis (H)\n",
    "- P(E) is the probability of the evidence (E)\n",
    "\n",
    "Q3:\n",
    "Bayes' theorem is used in practice in various applications, such as:\n",
    "\n",
    "- Classification: Naive Bayes classifiers use Bayes' theorem to predict the class of a new instance based on its features.\n",
    "- Regression: Bayes' theorem can be used to predict continuous outcomes, such as stock prices or temperatures.\n",
    "- Decision-making: Bayes' theorem can be used to update the probability of a decision based on new evidence.\n",
    "\n",
    "Q4:\n",
    "Bayes' theorem is closely related to conditional probability, which is the probability of an event given another event. Bayes' theorem provides a way to update the probability of a hypothesis based on new evidence, which is a form of conditional probability.\n",
    "\n",
    "Q5:\n",
    "The choice of Naive Bayes classifier depends on the type of data and the specific problem. Common types of Naive Bayes classifiers include:\n",
    "\n",
    "- Multinomial Naive Bayes: suitable for categorical features\n",
    "- Bernoulli Naive Bayes: suitable for binary features\n",
    "- Gaussian Naive Bayes: suitable for continuous features\n",
    "\n",
    "Q6:\n",
    "To classify the new instance using Naive Bayes, we need to calculate the posterior probability of each class given the features. Assuming equal prior probabilities for each class, we can calculate the posterior probabilities as follows:\n",
    "\n",
    "P(A|X1=3, X2=4) = P(X1=3|A) * P(X2=4|A) * P(A) / P(X1=3, X2=4)\n",
    "P(B|X1=3, X2=4) = P(X1=3|B) * P(X2=4|B) * P(B) / P(X1=3, X2=4)\n",
    "\n",
    "Using the frequencies from the table, we can calculate the posterior probabilities:\n",
    "\n",
    "P(A|X1=3, X2=4) = (4/10) * (3/10) * (1/2) / (1/2) = 0.24\n",
    "P(B|X1=3, X2=4) = (1/5) * (3/5) * (1/2) / (1/2) = 0.12\n",
    "\n",
    "Since P(A|X1=3, X2=4) > P(B|X1=3, X2=4), Naive Bayes would predict the new instance to belong to class A."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
