{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Here are the answers:\n",
    "\n",
    "Q1:\n",
    "The mathematical formula for a linear SVM is:\n",
    "\n",
    "w^T x + b = 0\n",
    "\n",
    "where w is the weight vector, x is the input vector, and b is the bias term.\n",
    "\n",
    "Q2:\n",
    "The objective function of a linear SVM is to minimize the hinge loss:\n",
    "\n",
    "L(w, b) = (1/n) * âˆ‘[max(0, 1 - y_i (w^T x_i + b))]\n",
    "\n",
    "where y_i is the label, x_i is the input vector, and n is the number of samples.\n",
    "\n",
    "Q3:\n",
    "The kernel trick in SVM is a method to transform the original input space into a higher-dimensional feature space where the data can be linearly separated. The kernel function maps the input data into a higher-dimensional space where the inner product can be computed.\n",
    "\n",
    "Q4:\n",
    "Support vectors are the data points that lie closest to the decision boundary. They play a crucial role in defining the margin of the classifier. Example: In a binary classification problem, the support vectors are the points that lie on the margin, which is the distance between the decision boundary and the closest data points.\n",
    "\n",
    "Q5:\n",
    "\n",
    "- Hyperplane: A hyperplane is a decision boundary that separates the classes.\n",
    "- Marginal plane: A marginal plane is a plane that passes through the support vectors and is parallel to the hyperplane.\n",
    "- Soft margin: A soft margin is a margin that allows for some misclassifications by introducing slack variables.\n",
    "- Hard margin: A hard margin is a margin that does not allow for any misclassifications.\n",
    "\n",
    "Graphs:\n",
    "\n",
    "- Hyperplane: A straight line that separates the classes.\n",
    "- Marginal plane: A plane that passes through the support vectors and is parallel to the hyperplane.\n",
    "- Soft margin: A margin that allows for some misclassifications, shown as a dashed line.\n",
    "- Hard margin: A margin that does not allow for any misclassifications, shown as a solid line.\n",
    "\n",
    "Q6:\n",
    "\n",
    "- Load the iris dataset from scikit-learn and split it into training and testing sets.\n",
    "- Train a linear SVM classifier on the training set and predict the labels for the testing set.\n",
    "- Compute the accuracy of the model on the testing set.\n",
    "- Plot the decision boundaries of the trained model using two of the features.\n",
    "\n",
    "Bonus task:\n",
    "\n",
    "- Implement a linear SVM classifier from scratch using Python.\n",
    "- Compare its performance with the scikit-learn implementation.\n",
    "- Try different values of the regularization parameter C and see how it affects the performance of the model.\n",
    "\n",
    "Note: The implementation and graphs are not provided here, but can be done using Python and scikit-learn library."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
