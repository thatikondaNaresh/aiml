{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Q1:\n",
    "\n",
    "Min-Max scaling, also known as normalization, is a technique used to scale data between a specific range, usually between 0 and 1. It is used to prevent features with large ranges from dominating the model. The formula for Min-Max scaling is:\n",
    "\n",
    "X_scaled = (X - X_min) / (X_max - X_min)\n",
    "\n",
    "Example: Suppose we have a dataset with a feature \"price\" ranging from $10 to $100. We want to scale it between 0 and 1.\n",
    "\n",
    "Price_min = 10\n",
    "Price_max = 100\n",
    "Price_scaled = (Price - Price_min) / (Price_max - Price_min)\n",
    "\n",
    "Q2:\n",
    "\n",
    "The Unit Vector technique, also known as normalization, is a technique used to scale data to have a length of 1. It is different from Min-Max scaling as it doesn't necessarily scale the data between a specific range. The formula for Unit Vector scaling is:\n",
    "\n",
    "X_scaled = X / ||X||\n",
    "\n",
    "Example: Suppose we have a dataset with a feature \"vector\" with values (3, 4). We want to scale it to have a length of 1.\n",
    "\n",
    "Vector_scaled = (3, 4) / sqrt(3^2 + 4^2)\n",
    "\n",
    "Q3:\n",
    "\n",
    "PCA (Principal Component Analysis) is a technique used to reduce the dimensionality of a dataset while retaining most of the information. It works by finding the directions of maximum variance in the data and projecting the data onto those directions.\n",
    "\n",
    "Example: Suppose we have a dataset with features \"height\" and \"weight\". We want to reduce the dimensionality to 1. PCA will find the direction of maximum variance and project the data onto that direction.\n",
    "\n",
    "Q4:\n",
    "\n",
    "PCA can be used for Feature Extraction by selecting the top k principal components that explain the most variance in the data. These components can be used as new features for the model.\n",
    "\n",
    "Example: Suppose we have a dataset with many features, and we want to extract the top 2 features that explain the most variance. We can use PCA to select those features.\n",
    "\n",
    "Q5:\n",
    "\n",
    "To use Min-Max scaling for the food delivery service dataset, we would scale the features \"price\", \"rating\", and \"delivery time\" between 0 and 1.\n",
    "\n",
    "Price_scaled = (Price - Price_min) / (Price_max - Price_min)\n",
    "Rating_scaled = (Rating - Rating_min) / (Rating_max - Rating_min)\n",
    "Delivery_time_scaled = (Delivery_time - Delivery_time_min) / (Delivery_time_max - Delivery_time_min)\n",
    "\n",
    "Q6:\n",
    "\n",
    "To use PCA for the stock price prediction dataset, we would first calculate the covariance matrix of the features. Then, we would calculate the eigenvectors and eigenvalues of the covariance matrix. We would select the top k eigenvectors corresponding to the top k eigenvalues and project the data onto those eigenvectors.\n",
    "\n",
    "Q7:\n",
    "\n",
    "To perform Min-Max scaling on the dataset [1, 5, 10, 15, 20] to transform the values to a range of -1 to 1, we would first calculate the minimum and maximum values.\n",
    "\n",
    "X_min = 1\n",
    "X_max = 20\n",
    "X_scaled = (X - X_min) / (X_max - X_min) * 2 - 1\n",
    "\n",
    "Q8:\n",
    "\n",
    "To perform Feature Extraction using PCA on the dataset [height, weight, age, gender, blood pressure], we would first calculate the covariance matrix of the features. Then, we would calculate the eigenvectors and eigenvalues of the covariance matrix. We would select the top k eigenvectors corresponding to the top k eigenvalues and project the data onto those eigenvectors.\n",
    "\n",
    "We would choose to retain 2-3 principal components, depending on the amount of variance explained by those components. This would reduce the dimensionality of the dataset while retaining most of the information."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
